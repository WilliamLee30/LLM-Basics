{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Torch中与tensor有关的最常用属性和函数有哪些？\n",
    "![](./images/torch_tensor创建.jpg)<br>\n",
    "![](./images/torch_tensor属性.jpg)<br>\n",
    "![](./images/torch_tensor索引和切片.jpg)<br>\n",
    "![](./images/torch_tensor数据类型转换.jpg)<br>\n",
    "![](./images/torch_tensor数据shape操作.jpg)<br>\n",
    "![](./images/torch_tensor算数计算.jpg)<br>\n",
    "![](./images/torch_tensorGPU和自动求导.jpg)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "'''Initializing  a Tensor'''\n",
    "# 1.Directly from data\n",
    "data = [\n",
    "        [1, 2],\n",
    "        [3, 4]\n",
    "]\n",
    "\n",
    "x_data = torch.tensor(data)\n",
    "\n",
    "print(x_data)\n",
    "print(type(x_data))\n",
    "print(x_data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "<class 'numpy.ndarray'>\n",
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n",
      "<class 'torch.Tensor'>\n",
      "torch.int32\n"
     ]
    }
   ],
   "source": [
    "# 2. From a Numpy array\n",
    "np_array = np.array(data)\n",
    "print(np_array)\n",
    "print(type(np_array))\n",
    "\n",
    "x_np = torch.from_numpy(np_array)\n",
    "print(x_np)\n",
    "print(type(x_np))\n",
    "print(x_np.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.初始化之后的tensor的dtype是由什么决定的？\n",
    "这个问题来源于上述代码的输出中，第一个输出的tensor没有带dtype,而第二个输出中带了。\n",
    "原因：<br>\n",
    "在Pytorch的Tensor中，默认的数据类型是:<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;(1)对于int类型：torch.int64<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;(2)对于float类型，torch.float32<br>\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;而在第一个例子中，是直接从数据生成的tensor，那么数据的类型也由tensor自动推断，默认就是torch.int64类型，而默认类型，在输出tensor时，是不显示的；<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;第二个例子中，因为是先从numpy.ndarray生成的，而ndarray对于int类型的默认dtype是np.int32，因此在生成tensor时，会自动推断为torch.int32，导致不是tensor的默认数据类型，因此会显示地输出。<br>\n",
    "\n",
    "# 2.如何转换tensor和numpy的dtype？\n",
    "![tensor和ndarray的dtype转换方法](./images/tensor和ndarray的dtype转换方法.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1],\n",
      "        [1, 1]])\n",
      "tensor([[0.1039, 0.2464],\n",
      "        [0.9373, 0.6347]])\n"
     ]
    }
   ],
   "source": [
    "# 3.From another tensor\n",
    "# 新建的tensor会保留原有的属性（shape和datatype），除非显示地重写 \n",
    "x_ones = torch.ones_like(x_data)\n",
    "print(x_ones)\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype = torch.float) #override the datatype\n",
    "print(x_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6092, 0.1209, 0.3179],\n",
      "        [0.3937, 0.3992, 0.8875]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "#  4.With random or constant values\n",
    "# Shpe is a tuple of tensor dimensions\n",
    "shape = (2,3)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(rand_tensor)\n",
    "print(ones_tensor)\n",
    "print(zeros_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4])\n",
      "torch.float32\n",
      "cpu\n",
      "cuda:0\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "'''Attrbutes of a Tensor'''\n",
    "tensor = torch.rand(3, 4)\n",
    "print(tensor.shape)\n",
    "print(tensor.dtype)\n",
    "print(tensor.device)\n",
    "\n",
    "# 移动tensor的操作，都会返回新的移动之后的tensor，而不会改变原有的tensor，这是pytorch的\n",
    "# 内部设置,是为了避免accidental overwriting, ensuring explicit control over where computations happen.\n",
    "tensor_gpu = tensor.to(\"cuda\") \n",
    "tensor_gpu_1 = tensor.cuda()\n",
    "print(tensor_gpu.device)\n",
    "print(tensor_gpu_1.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# 用于判断Cuda是否可用，以及GPU的设置 \n",
    "print(torch.cuda.is_available())  # True if a GPU is available\n",
    "print(torch.cuda.device_count())  # Number of GPUs available\n",
    "print(torch.cuda.get_device_name(0))  # Name of the first GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Operations on Tensors'''\n",
    "if torch.accelerator.is_available():\n",
    "    tensor = tensor.to(torch.accelerator.current_accelerator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1.])\n",
      "tensor([1., 1., 1., 1.])\n",
      "tensor([1., 1., 1., 1.])\n",
      "tensor([1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "tensor([[[0.5909, 0.2303, 0.0955, 0.9692],\n",
      "         [0.7367, 0.7870, 0.3499, 0.6610],\n",
      "         [0.6881, 0.5135, 0.5637, 0.6185],\n",
      "         [0.0351, 0.0614, 0.6553, 0.3489]],\n",
      "\n",
      "        [[0.5170, 0.7386, 0.5188, 0.9104],\n",
      "         [0.3352, 0.6535, 0.8963, 0.9468],\n",
      "         [0.6955, 0.2645, 0.5405, 0.0114],\n",
      "         [0.9743, 0.0647, 0.3262, 0.5512]],\n",
      "\n",
      "        [[0.5151, 0.0262, 0.4394, 0.6635],\n",
      "         [0.8396, 0.2170, 0.9283, 0.8664],\n",
      "         [0.5285, 0.9629, 0.5405, 0.8921],\n",
      "         [0.7249, 0.0570, 0.9306, 0.0887]]])\n",
      "tensor([[0.9692, 0.6610, 0.6185, 0.3489],\n",
      "        [0.9104, 0.9468, 0.0114, 0.5512],\n",
      "        [0.6635, 0.8664, 0.8921, 0.0887]])\n"
     ]
    }
   ],
   "source": [
    "# 1.Standard numpy-like indexing and slicing:\n",
    "tensor = torch.ones(4, 4)\n",
    "print(tensor[0])\n",
    "print(tensor[:, 1])\n",
    "\n",
    "print(tensor[:, -1])\n",
    "print(tensor[..., -1])\n",
    "\n",
    "tensor[:, 1] = 0\n",
    "print(tensor)\n",
    "\n",
    "tensor_3d = torch.rand(3, 4, 4)\n",
    "print(tensor_3d)\n",
    "print(tensor_3d[..., -1])  # Selects the last column from each 2D slice\n",
    "\n",
    "# Note:\n",
    "# \"...\" 指的是slice 前面所有的维度；\n",
    "# 当是2维数组时，tensor[:, -1]等价于tensor[..., -1]\n",
    "# 如果是3维数组，tensor[..., -1]等价于tensor[:, :, -1]\n",
    "# 如果是n维数组，tensor[..., -1]等价于tensor[:, :, 重复,:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Joining tensors\n",
    "t1 = torch.cat([tensor, tensor, tensor], dim = 1)\n",
    "print(t1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://blog.csdn.net/weixin_39504171/article/details/106074550\n",
    "https://blog.csdn.net/qq_40507857/article/details/119854085"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
