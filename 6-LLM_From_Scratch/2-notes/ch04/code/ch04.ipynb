{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7482670",
   "metadata": {},
   "source": [
    "# 1.GPT模型的架构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "158cee6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''124M GPT-2的参数设置'''\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50527, #vocabulary size\n",
    "    \"context_length\": 1024, #context length\n",
    "    \"emb_dim\": 768, #embedding dimension\n",
    "    \"n_heads\": 12, #number of attention heads\n",
    "    \"n_layers\": 12, #number of layers(transformer blocks)\n",
    "    \"drop_rate\": 0.1, #dropout rate\n",
    "    \"qkv_bias\": False #query-key-value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52db9e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''一个虚拟的GPT模型的架构'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        #Transformer block\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "\n",
    "        #Layer Normalization\n",
    "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])\n",
    "        \n",
    "        #Output\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias = False\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_length = in_idx.shape\n",
    "\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_length, device = in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "       \n",
    "        x = self.drop_emb(x)\n",
    "\n",
    "        x= self.trf_blocks(x)\n",
    "\n",
    "        x = self.final_norm(x)\n",
    "\n",
    "        logits = self.out_head(x)\n",
    "\n",
    "        return logits\n",
    "\n",
    "\n",
    "class DummyTransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        # Implementation of transformer blocks\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        return x\n",
    "\n",
    "class DummyLayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, eps = 1e-5):\n",
    "        super().__init__()\n",
    "        #The implementation of layer normalization\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4432dd12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "'''测试虚拟的GPT模型的输出'''\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "# 1.构造数据\n",
    "tokenizer  = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "batch = []\n",
    "\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "\n",
    "batch = torch.stack(batch, dim = 0)\n",
    "\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c59b3f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 50527])\n",
      "tensor([[[-0.5076,  0.5526, -1.3087,  ..., -1.2430, -0.1799,  0.2840],\n",
      "         [ 0.4162,  0.5258, -0.2680,  ..., -0.6662, -0.0434, -1.7204],\n",
      "         [ 0.2720,  0.5737,  0.2196,  ..., -0.4875, -2.2169, -0.8551],\n",
      "         [ 1.7329, -0.0533,  0.9222,  ..., -0.8311, -0.3060,  0.1644]],\n",
      "\n",
      "        [[-0.4748,  1.0586, -0.6434,  ..., -0.9168,  0.2064, -0.3204],\n",
      "         [-0.4063, -0.6273,  0.9828,  ..., -0.6344,  0.0545, -0.0326],\n",
      "         [-0.2660, -1.7609,  0.6074,  ..., -1.1383, -0.7710, -0.9709],\n",
      "         [ 0.5479, -1.3437,  1.2603,  ...,  0.6285, -0.2088, -2.5608]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "model =  DummyGPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "logits = model(batch)\n",
    "\n",
    "print(logits.shape)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ea0240",
   "metadata": {},
   "source": [
    "# 2.Layer Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6064aae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
      "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "'''得到神经网络某一层的输出激活值'''\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# create 2 training examples with 5 dimensions (features) each\n",
    "batch_example = torch.randn(2, 5) \n",
    "\n",
    "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
    "out = layer(batch_example)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e23495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1324],\n",
      "        [0.2170]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0231],\n",
      "        [0.0398]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#查看输出激活值的均值和方差\n",
    "mean = out.mean(dim = -1, keepdim = True) #keepdim参数的作用是使输出的维度和原始的维度保持一致\n",
    "var = out.var(dim = -1, keepdim = True)\n",
    "\n",
    "print(mean)\n",
    "print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cb88fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6159,  1.4126, -0.8719,  0.5872, -0.8719, -0.8719],\n",
      "        [-0.0189,  0.1121, -1.0876,  1.5173,  0.5647, -1.0876]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "Mean:\n",
      " tensor([[9.9341e-09],\n",
      "        [5.9605e-08]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "'''使得均值为0 方差为1 的方法：减去均值并且除以方差的平方根'''\n",
    "out_norm = (out - mean) / torch.sqrt(var)\n",
    "print(out_norm)\n",
    "\n",
    "mean = out_norm.mean(dim=-1, keepdim=True)\n",
    "var = out_norm.var(dim=-1, keepdim=True)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2853531e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0.0000],\n",
      "        [    0.0000]], grad_fn=<MeanBackward1>)\n",
      "tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 注意到上面进行normalization之后，均值并不严格为0，而是接近0的一个小数。\n",
    "# 可以通过下面的方式实现：禁用科学计算\n",
    "torch.set_printoptions(sci_mode = False)\n",
    "print(mean)\n",
    "print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9eafda62",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Layer Normalization的实现'''\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5 #用于避免出现除以0的情况\n",
    "        # 下面这两个参数是可学习的参数，用于在训练过程中提升模型的性能\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim = -1, keepdim = True)\n",
    "        var = x.var(dim = -1, keepdim = True, unbiased = False)\n",
    "        \n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c105da41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[    -0.0000],\n",
      "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 测试layer normalization\n",
    "ln = LayerNorm(emb_dim = 5)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# create 2 training examples with 5 dimensions (features) each\n",
    "batch_example = torch.randn(2, 5) \n",
    "out_ln = ln(batch_example)\n",
    "\n",
    "mean = out_ln.mean(dim=-1, keepdim=True)\n",
    "var = out_ln.var(dim=-1, unbiased=False, keepdim=True)\n",
    "\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7317420",
   "metadata": {},
   "source": [
    "# 3.带GELU激活函数的FFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b525722",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''GELU函数的代码实现'''\n",
    "import torch.nn as nn\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "            (x + 0.44715 * torch.pow(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecca0579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxYAAAEiCAYAAABkykQ1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAABVt0lEQVR4nO3deVxU9foH8M+wDTuKCiiL4oY7CoihZXhTcWmhhcoyNdO0tFy6pngr025Rmak392vKL5NcU7tmJpGk5gqCCiaFgoisyjKswzBzfn8gJALKMAznzPB5v16+bnPmnJnncbx8eeZ7nu9XJgiCACIiIiIiIh2YiB0AEREREREZPhYWRERERESkMxYWRERERESkMxYWRERERESkMxYWRERERESkMxYWRERERESkMxYWRERERESkMxYWRERERESkMxYWRERERESkMxYWRERERESkMxYWRE2QkpKC2bNno2fPnrC2toa1tTX69OmDWbNm4eLFizXnffjhh5DJZA3+ycrKAgCkpqZCJpPhiy++aPA9u3Tpgscff7ze52JiYiCTyRAeHt6seRIRkXbCw8Nr/Zw3MzODq6srpkyZgps3b2r9etHR0ZDJZNizZ0+D58hkMsyePbve5/bs2QOZTIbo6Git35tIW2ZiB0BkaA4ePIgXXngBZmZmePnll+Ht7Q0TExNcuXIF33//PdavX4+UlBR07ty55pr169fD1ta2zmu1adOmBSMnIqKWsmzZMnh6eqK8vBynT59GeHg4Tpw4gYSEBFhaWoodHpFesLAg0sLVq1fx4osvonPnzoiKikLHjh1rPf/ZZ59h3bp1MDGpPRn43HPPoX379i0ZKhERiWjs2LHw8/MDAEybNg3t27fHZ599hh9++AHPP/+8yNER6QdvhSLSwueff46SkhJs3bq1TlEBAGZmZnj77bfh7u4uQnRERCRVjzzyCICqL6iqXblyBc899xwcHR1haWkJPz8//PDDD2KFSKQzzlgQaeHgwYPo3r07hgwZotV1eXl5dY6ZmZnxVigiolYiNTUVANC2bVsAQGJiIoYNGwZXV1csWrQINjY22LVrF4KDg7F37148/fTTIkZL1DQsLIgaSaFQICMjA8HBwXWeKygoQGVlZc1jGxsbWFlZ1Tz28vKqc42XlxeuXLmil1iJiEhchYWFuHXrFsrLy3HmzBksXboUcrm8ZhGOOXPmwMPDA+fOnYNcLgcAvPnmm3j44YexcOFCFhZkkFhYEDWSQqEAgHqbsAMDA3HhwoWax8uXL8c///nPmsd79+6Fvb19rWtsbGz0FCkREYlt5MiRtR536dIF3377Ldzc3JCXl4dff/0Vy5YtQ1FREYqKimrOCwoKwpIlS3Dz5k24urq2dNhEOmFhQdRIdnZ2AIDi4uI6z23cuBFFRUXIzs7GxIkT6zw/fPjwFmnelslken8PIiJ6sLVr16Jnz54oLCzEli1bcOzYsZqZieTkZAiCgPfffx/vv/9+vdfn5OQ0a2HB8YFaAgsLokZycHBAx44dkZCQUOe56p6L6nto9cHS0hJlZWX1PldaWlpzDhERic/f379mVajg4GA8/PDDeOmll5CUlASNRgMA+Oc//4mgoKB6r+/evXuj30sul3N8IElgYUGkhfHjx2Pz5s04e/Ys/P39W/S9O3fujMuXL9f7XFJSUs05REQkLaampggLC8OIESOwZs0aTJ06FQBgbm5e55appujcuXPNOHAvjg/UkrjcLJEW3n33XVhbW2Pq1KnIzs6u87wgCHp773HjxiE9PR379++vdVypVGLz5s1wcnKCj4+P3t6fiIiaLjAwEP7+/li1ahXs7e0RGBiIjRs3IjMzs865ubm5Wr32uHHjcPr0acTGxtY6XlBQgO3bt2PgwIFwcXHRKX6ixuCMBZEWevTogYiICEyYMAFeXl41O28LgoCUlBRERETAxMQEbm5uta7bs2dPvU3fo0aNgrOzc83jqKgolJeX1zkvODgYr7/+OrZs2YKQkBBMnToVgwYNwu3bt7Fz504kJCTgm2++gYWFRfMnTUREzWLBggUICQlBeHg41q5di4cffhj9+/fH9OnT0bVrV2RnZ+PUqVNIT0+vtSAIULUISH0rCU6ePBmLFi3C7t27MXz4cMyYMQO9evVCRkYGwsPDkZmZia1bt7ZUitTaCUSkteTkZOGNN94QunfvLlhaWgpWVlZCr169hJkzZwrx8fE15y1ZskQA0OCfo0ePCoIgCCkpKfc9b9u2bYIgCEJ+fr4wb948wdPTUzA3Nxfs7e2FESNGCD/99JMYfw1ERHSPrVu3CgCEc+fO1XlOrVYL3bp1E7p16yZUVlYKV69eFSZNmiS4uLgI5ubmgqurq/D4448Le/bsqbnm6NGj9x0fjh8/LgiCIKSnpwvTpk0TXF1dBTMzM8HR0VF4/PHHhdOnT7dY7kQyQdDjvRtERERERNQqsMeCiIiIiIh0xsKCiIiIiIh0xsKCiIiIiIh0xsKCiIiIiIh0xsKCiIiIiIh0xsKCiIiIiIh01uo2yNNoNMjIyICdnR1kMpnY4RARSYIgCCgqKkKnTp1gYtJ6v3PiGEFEVJs240OrKywyMjLg7u4udhhERJJ048aNOjvHtyYcI4iI6teY8aHVFRZ2dnYAqv5y7O3ttbpWpVLhyJEjGD16NMzNzfURXoswhjyYg3QYQx7GkAOgWx4KhQLu7u41PyNbq9Y+RjAH6TCGPIwhB8A48mip8aHVFRbVU9v29vZNGjSsra1hb29vsP+wAOPIgzlIhzHkYQw5AM2TR2u//ae1jxHMQTqMIQ9jyAEwjjxaanxovTfSEhERERFRs2FhQUREREREOhO1sFi/fj0GDBhQM+UcEBCAn3766b7X7N69G7169YKlpSX69++PQ4cOtVC0RETUUjg+EBEZHlELCzc3N3z66aeIjY1FTEwM/vGPf+Cpp55CYmJiveefPHkSEyZMwGuvvYa4uDgEBwcjODgYCQkJLRw5ERHpE8cHIiLDI2ph8cQTT2DcuHHo0aMHevbsiY8//hi2trY4ffp0veevXr0aY8aMwYIFC9C7d2989NFH8PHxwZo1a1o4ciIi0ieOD0REhkcyPRZqtRo7duxASUkJAgIC6j3n1KlTGDlyZK1jQUFBOHXqVEuESEQkWSq1Bkv+dxm3y8WOpPlxfCAi0s3xv27h1wwZBEHQ6/uIvtzspUuXEBAQgPLyctja2mLfvn3o06dPvedmZWXB2dm51jFnZ2dkZWU1+PpKpRJKpbLmsUKhAFC17JZKpdIq1urztb1OaowhD+YgHcaQh6HnIAgCPjz4ByLOpsNRbopnxilho+VrSDF3fY8PAMeIezEH6TCGPIwhB8Dw87ieV4q5uy5CUW4Kv3NpeNG/s1bXa5O36IWFl5cX4uPjUVhYiD179mDy5Mn47bffGhw8tBUWFoalS5fWOX7kyBFYW1s36TUjIyN1DUsSjCEP5iAdxpCHoeZwLFOGvammkEHAM100+O3XKK1fo7S0VA+R6Ubf4wPAMaIhzEE6jCEPY8gBMMw8lGpgZYIpFOUydLYVYJ2TiEOH6u9Va4g244PohYWFhQW6d+8OAPD19cW5c+ewevVqbNy4sc65Li4uyM7OrnUsOzsbLi4uDb5+aGgo5s+fX/O4evfA0aNHN2nzo8jISIwaNcpgN0gBjCMP5iAdxpCHIedw/K9b2Hf6PABg/sju8ChJalIe1d/US4m+xweAY8S9mIN0GEMexpADYLh5CIKAubsuIrM0G+1sLDC1ZynGBul3fBC9sLiXRqOpNS19t4CAAERFRWHu3Lk1xyIjIxu85xYA5HI55HJ5nePm5uZN/sehy7VSYgx5MAfpMIY8DC2H5JwizNl5ERoBCPF1w4zhXfHTT0lNysMQ8m7u8QHgGNEQ5iAdxpCHMeQAGF4eG3+7ikMJ2TAzkWHNBG/kJJ7S+/ggamERGhqKsWPHwsPDA0VFRYiIiEB0dDR+/vlnAMCkSZPg6uqKsLAwAMCcOXPw6KOPYsWKFRg/fjx27NiBmJgYbNq0Scw0iIhaXF5JBaaGx6BIWQn/Lo7499P9IBM0YofVbDg+EBE13fG/cvHZ4SsAgCVP9oVf57bQ8g6oJhG1sMjJycGkSZOQmZkJBwcHDBgwAD///DNGjRoFAEhLS4OJyd8LVw0dOhQRERF47733sHjxYvTo0QP79+9Hv379xEqBiKjFVVRqMPPbWKTllcLd0QobXvGF3MwUKpXxFBYcH4iImibtdilmR8RBIwDP+7lh4hAPVFZWtsh7i1pYfP311/d9Pjo6us6xkJAQhISE6CkiIiJpEwQB7+9PwNmUPNjJzbBl8mA42liIHVaz4/hARKS90opKvL4tBoVlKni7OWDZU/0gk8la7P0ls48FERE92ObjKdgZcwMmMuCrlwahh7Od2CEREZEECIKARXsv4UpWEdrbWmDDK76wNDdt0RhYWBARGYioP7LxyU9/AADeG98HgV5OIkdERERSsfl4Cn64kAEzExnWvuSDjg5WLR4DCwsiIgNwJUuBt7+LgyAALw3xwKvDuogdEhERScSJv24h7M4XT+8/3gdDurYTJQ4WFkREEnerWInXwmNQUqHG0G7tsPTJvi16zywREUnXjbxSvPXdeWgE4FkfN0wK0G5n7ebEwoKISMLKVWrM2BaLmwVl8Gxvg3Uv+8DclD+6iYgIKKuoGiPyS1UY4OaAj59u2Wbte3F0IiKSKEEQsPj7S4i9ng97SzNsnuyHNtbGtwIUERFpTxAEhH5/EZczFWhnY4ENE1u+WfteLCyIiCRqXfRVfB93E6YmMqx72RfdOtiKHRIREUnElt9TsT8+A6YmMqx5yQed2rR8s/a9WFgQEUnQ4YRMLP85CQCw9Mm+eLhHe5EjIiIiqTh59RY+OVS9SmBvBHQTp1n7XiwsiIgkJuFmIebtvAAAmDK0CyY+JF4jHhERSUt6ftXO2mqNgGcGuWLK0C5ih1SDhQURkYTkKMox/ZsYlKnUGN6zA94b31vskIiISCLKVWrM/DYWeSUV6NvJHp88019SqwSysCAikohylRrTv4lBZmE5ujvZYs1Lg2DGFaCIiAh3FvTYdwkJNxVwtLHARhF21n4QjlhERBIgCAL+ufsCLqQXoo21Ob6e7Ad7S3OxwyIiIokIP5mK78/fvNOsPQhuba3FDqkOFhZERBKwOuovHLyYCXNTGTZM9EXndjZih0RERBJx+tpt/PvHqmbt0LG9MLSbNBf0YGFBRCSy/13IwKpf/gIA/Du4Hx7qKo3VPYiISHwZBWWYtf081BoBwQM74bWHPcUOqUEsLIiIRHThRgH+ubtqBajpj3jihcEeIkdERERSUd2sfbukAn062iPsmQGSata+FwsLIiKRZBaWYfo3MVBWavBYLycsGssVoIiIqIogCPjXvgRcvNN7t/EVX1hZSKtZ+14sLIiIRFBaUYlp/xeDnCIlvJztsHrCIJiaSPdbKCIialnbTl/H3vPpMJEBayb4wN1Res3a92JhQUTUwjQaAfN3XkBihgLtbCywebIfbOVmYodFREQScebabSz732UAQOjY3ni4hzSbte/FwoKIqIWtiEzC4cQsWJiaYOMrvgbxLRQREbWMzMIyzIo4j0qNgCe8O2HaI9Jt1r6XqIVFWFgYBg8eDDs7Ozg5OSE4OBhJSUn3vSY8PBwymazWH0tLyxaKmIhIN/vi0rH26FUAwKfP9odfF0eRIyIiIqmoatY+j1vFFejlYofPnpXWztoPImph8dtvv2HWrFk4ffo0IiMjoVKpMHr0aJSUlNz3Ont7e2RmZtb8uX79egtFTETUdLHX87FwzyUAwJuB3fCMj5vIEUkXv3giotZGEAR8cCABF24UoI21Of47yQ/WFoZ1m6yo0R4+fLjW4/DwcDg5OSE2NhbDhw9v8DqZTAYXFxd9h0dE1GzS80sxY1sMKtQaBPV1xj9He4kdkqRVf/E0ePBgVFZWYvHixRg9ejQuX74MG5uGNw+0t7evVYAY0jd9RNS6fXsmDbtiqpq1v5owyCBvk5VUGVRYWAgAcHS8/60BxcXF6Ny5MzQaDXx8fPDJJ5+gb9++9Z6rVCqhVCprHisUCgCASqWCSqXSKr7q87W9TmqMIQ/mIB3GkIe+cyhWVuK18HO4VVyB3i52+PyZvlCrK6FWN+/76JKH1D4/fvFERK3JudQ8LP0hEQDw7pheeKRHB5EjahrJFBYajQZz587FsGHD0K9fvwbP8/LywpYtWzBgwAAUFhbiiy++wNChQ5GYmAg3t7q3FYSFhWHp0qV1jh85cgTW1k2rBCMjI5t0ndQYQx7MQTqMIQ995KARgM1JJkjKN4G9uYAXOuUj+pcjzf4+d2tKHqWlpXqIpPno44snIiIpyCosxxvfVjVrjx/QETOGdxU7pCaTTGExa9YsJCQk4MSJE/c9LyAgAAEBATWPhw4dit69e2Pjxo346KOP6pwfGhqK+fPn1zxWKBRwd3fH6NGjYW9vr1WMKpUKkZGRGDVqFMzNzbW6VkqMIQ/mIB3GkIc+c/j0cBIS869DbmaCLVMHw9vNoVlf/2665FE9mytF+vriCeCs9r2Yg3QYQx7GkAOg3zyUlRrM/DYGt4qV8HK2xSdP9UZlZWWzv09LzWhLorCYPXs2Dh48iGPHjjX4w78h5ubmGDRoEJKTk+t9Xi6XQy6X13tdU3+B0OVaKTGGPJiDdBhDHs2dw65zN/D171WLS3wR4g0/z5ZZh7wpeUj5s9PXF08AZ7UbwhykwxjyMIYcAP3kseOqCeJzTGBlKuD5TgUGP6MtamEhCALeeust7Nu3D9HR0fD01H6dXrVajUuXLmHcuHF6iJCIqGnOXLuNf+2vWgFqzmM98IR3J5EjMkz6/OIJ4Kz2vZiDdBhDHsaQA6C/PHacS8epU5chkwFrXvbFcD1ugtdSM9qiFhazZs1CREQEDhw4ADs7O2RlZQEAHBwcYGVlBQCYNGkSXF1dERYWBgBYtmwZHnroIXTv3h0FBQVYvnw5rl+/jmnTpomWBxHR3dJul2Lmt7FQqavul53zWA+xQzI4LfXFE2e168ccpMMY8jCGHIDmzSP2eh6W/fgHAGBBkBce69OxWV73QfQ9oy1qYbF+/XoAQGBgYK3jW7duxZQpUwAAaWlpMDH5e7uN/Px8TJ8+HVlZWWjbti18fX1x8uRJ9OnTp6XCJiJqkKJchan/dw75pSp4uzlgRYg3TEy45Km2+MUTERmrbEU5Zn57Hiq1gHH9XfDGo93EDqnZiH4r1INER0fXerxy5UqsXLlSTxERETVdpVqD2RFxSM4phou9JTZN8oOluanYYRkkfvFERMaoolKDN76NRW6REj2dbbH8OW+j2m9HEs3bRETG4ONDf+DYn7mwMjfF5sl+cLbnrs9NxS+eiMgYLf1fIs6nFcDe0gybXvGDjdy4fhU3efApRET0INvPXMfW31MBACtf8EY/V/0tK0tERIZnx9k0bD+TBpkMWP3iIHRpbyN2SM2OhQURkY5OJt/CBweqdkxdEOSFMf1apgmPiIgMw/m0/Jpx4p1RPTGil5PIEekHCwsiIh1cyy3GG9vPQ60R8PQgV7wZaDxNeEREpLuconK88W0sKtQaBPV1xpuB3cUOSW9YWBARNVFhqQrT/i8GhWUq+Hi0Qdgz/Y2qCY+IiHRTUanBm9+eR7ZCie5Otljx/ECjXimQhQURUROo1Bq8GRGLa7dK4NrGChtf4QpQRERU20cHLyPmej7s5GbY9IovbI2sWfteLCyIiLQkCAI+/CERvyffho1F1QpQHezqbrJGRESt165zN7Dt9HXIZMCqFweiawdbsUPSOxYWRERa+r+TqbVW9ujd0V7skIiISELibxTgvf0JAIB5I3visd7OIkfUMlhYEBFpITopB8sOXgYAhI7thZF9WsdgQUREjZNbpMTMbVXN2qP6OGP2CONt1r4XCwsiokZKzinCWxFx0AhAiK8bpj/SVeyQiIhIQlRqDWZtP48sRTm6dbDBl897G3Wz9r1YWBARNUJeSQWmhsegSFkJf09HfPw0V4AiIqLaPv7xD5xNzYOt3AybJvnBztJc7JBaFAsLIqIHqKjUYOa3sUjLK4W7oxU2TPSFhRl/fBIR0d92x9xA+MlUAMDKFwaiWyto1r4XR0YiovsQBAHv7b+Esyl5sJObYcvkwXC0sRA7LCIikpCL6QX4151m7TmP9cCoVtp/x8KCiOg+Nh9Pwa6YdJjIgK9eGoQeznZih0RERBJyq/hOs3alBiN7O2HOYz3EDkk0LCyIiBoQ9Uc2PvnpDwDA+4/3QaCXk8gRERGRlFQ3a2cUlqNrext8+YJx76z9ICwsiIjqcSVLgbe/i4MgAC8N8cCUoV3EDomIiCTmk0N/4ExKHmwsTLFpki/sW1mz9r1YWBAR3eNWsRKvhcegpEKNod3aYemTfbkCFBER1fL9+XRs/T0VAPDlCwPR3Ym3yrKwICK6S7lKjRnbYnGzoAye7W2w7mUfmJvyRyUREf0t4WYhQr+/BAB4+x/dEdTXReSIpEHU0TIsLAyDBw+GnZ0dnJycEBwcjKSkpAdet3v3bvTq1QuWlpbo378/Dh061ALREpGxEwQBi7+/hNjr+bC3NMPXk/3QxporQBER0d9uFysxY1sslJUajPDqgLkje4odkmSIWlj89ttvmDVrFk6fPo3IyEioVCqMHj0aJSUlDV5z8uRJTJgwAa+99hri4uIQHByM4OBgJCQktGDkRGSMNh5LwfdxN2FqIsP6ib7o2grXICciooZVqjWYHRFXM6u96sVBrbpZ+15mYr754cOHaz0ODw+Hk5MTYmNjMXz48HqvWb16NcaMGYMFCxYAAD766CNERkZizZo12LBhg95jJiLjdOG2DFtOJQMAlj7ZF8O6txc5IiIikppPf7qCU9duVzVrv+ILB6vW3ax9L0ndOFxYWAgAcHR0bPCcU6dOYeTIkbWOBQUF4dSpU3qNjYiMV2KGAt8mV/04nDK0CyY+1FnkiIi3yhKR1PxwIRObT6QAAFY87819jeoh6ozF3TQaDebOnYthw4ahX79+DZ6XlZUFZ+fauxk6OzsjKyur3vOVSiWUSmXNY4VCAQBQqVRQqVRaxVh9vrbXSY0x5MEcpMPQ88gpUmLm9jhUaGR4uJsjFo7ubrC56PJZSC3n6ltlBw8ejMrKSixevBijR4/G5cuXYWNjU+811bfKhoWF4fHHH0dERASCg4Nx/vz5+44rREQPkl4CfHUgEQAwa0Q3jOnXUeSIpEkyhcWsWbOQkJCAEydONOvrhoWFYenSpXWOHzlyBNbW1k16zcjISF3DkgRjyIM5SIch5lGhBr5KNEVWiQzOVgIed8zBkZ8PP/hCiWvKZ1FaWqqHSJqOt8oSkVTklVTg6yRTlKs0CPTqgPmjvMQOSbIkUVjMnj0bBw8exLFjx+Dm5nbfc11cXJCdnV3rWHZ2Nlxc6l/mKzQ0FPPnz695rFAo4O7ujtGjR8Pe3l6rOFUqFSIjIzFq1CiYmxvuPXXGkAdzkA5DzUMQBMzbfQlpJVloY2WO13uV4cmxhpXDvXT5LKpnc6WqsbfK3v3zHqi6VXb//v36DI2IjFilWoN5uy4iTymDh6MVVr8wCKZs1m6QqIWFIAh46623sG/fPkRHR8PT0/OB1wQEBCAqKgpz586tORYZGYmAgIB6z5fL5ZDL5XWOm5ubN/kXCF2ulRJjyIM5SIeh5fFV1F/48VIWzExkWDPBG7f/OG1wOTSkKXlIOW993SoL8HbZezEH6TCGPIwhh08PJ+HktTxYmAj46vl+sDY3zHxa6lZZUQuLWbNmISIiAgcOHICdnV3ND38HBwdYWVkBACZNmgRXV1eEhYUBAObMmYNHH30UK1aswPjx47Fjxw7ExMRg06ZNouVBRIblcEImVkT+CQD4d3A/DPF0xKE/RA6KGqSvW2UB3i7bEOYgHcaQh6HmcP6WDP/3lykA4KXuGqReOIXUCyIHpSN93yoramGxfv16AEBgYGCt41u3bsWUKVMAAGlpaTAx+XvxqqFDhyIiIgLvvfceFi9ejB49emD//v1szCOiRknMKMS8nVUjw6vDuuBFfw+D/PaptdDnrbIAb5e9F3OQDmPIw5Bz+COzCAv/ewaABtOGeaC/5ppB5lGtpW6VFf1WqAeJjo6ucywkJAQhISF6iIiIjFlukRLT/y8GZSo1HunRHv8a11vskKgBLXGrLMDbZRvCHKTDGPIwtBzySyowa0c8ylUaPNKjPf452gs/H75mcHnUR9+3ykqieZuISN+UlWrM2BaDjMJydG1vgzUv+cDMVFJb+dBdeKssEYlBrRHw9o443Mgrg4ejNb6awGZtbXBUJSKjJwgCQr+/hPNpBbC3NMPmyX7cLVXi1q9fj8LCQgQGBqJjx441f3bu3FlzTlpaGjIzM2seV98qu2nTJnh7e2PPnj28VZaItLL85yQc/+sWrMxNsfEVX7SxthA7JIPSpBmLlJQUHD9+HNevX0dpaSk6dOiAQYMGISAgAJaWls0dIxGRTjYdu4bvz9+EqYkM6172RdcOtmKHRA/AW2WJqKUdvJiBDb9dBQB8/twA9O6oXZ8VaVlYbN++HatXr0ZMTAycnZ3RqVMnWFlZIS8vD1evXoWlpSVefvllLFy4EJ07d9ZXzEREjRb1RzY+PXwFALDkiT54uEd7kSMiIiKpuZKlwILdFwEAM4Z3xRPenUSOyDA1urAYNGgQLCwsMGXKFOzduxfu7u61nlcqlTh16hR27NgBPz8/rFu3jt8aEZGokrKK8PZ3cRAE4OUhHnjlIX7h0RI4q01EhqSgtAKvfxNbs7DHu2N6iR2SwWp0YfHpp58iKCioweflcjkCAwMRGBiIjz/+GKmpqc0RHxFRk+SVVGDaN+dQUqHGQ10d8eGTfSGTsQFPnzirTUSGpqpZOx5peaVwa2uF/7zIZm1dNLqwuF9Rca927dqhXbt2TQqIiEhXFZUavPFtbM2qHutf9oU5V4DSK85qE5EhWnEkCcf+zIWluQk2vuKLtjZs1tZFk0ba8PDweo9XVlYiNDRUl3iIiHQiCAKW/JCAMyl5sJWb4evJfhwoWsCnn36KM2fO4M0336xTVAB/z2pv2LABV65cQdeuXUWIkojob4cuZWJddFWz9mfPDkDfTg4iR2T4mlRYvP322wgJCUF+fn7NsaSkJAwZMgTfffddswVHRKSt8JOp+O7sDchkwFcTBqGHs53YIbUK2s5q+/r66jEaIqL7S8oqwj93XwAATH/EE08NdBU5IuPQpMIiLi4O6enp6N+/PyIjI7F27Vr4+PigV69euHDhQnPHSETUKMf+zMVHBy8DABaP7Y0RvZxEjqh14qw2EUlZYakKr2+LQWmFGkO7tcNCNms3myYVFt26dcPvv/+OZ555BmPGjMG8efOwefNmbN++HQ4OnEYiopZ3LbcYsyLOQyMAz/m6YdojnmKH1GpxVpuIpEqtETBnZxyu3y6FaxsrrHnJB2bswWs2Tf6b/PHHH7Fjxw4EBASgTZs2+Prrr5GRkdGcsRERNUpRuQqvb4tFUXklfDu3xcdP9+MKUCLirDYRSdWqX/5EdFIu5GZVzdqO7MFrVk0qLGbMmIGQkBAsXLgQx48fx8WLF2FhYYH+/ftj165dzR0jEVGDNBoB83ZeQHJOMVzsLbF+og/kZqZih9WqcVabiKTocEImvvo1GQDw6bP90c+VP4+aW5MKi99//x1nzpzBO++8A5lMBhcXFxw6dAjLli3D1KlTmztGIqIGrYr6C7/8kQ2LO98+OdlxAzYp4Kw2EUnJX9lFeGdX1Yzp1GGeeHqQm8gRGacmFRaxsbHw9vauc3zWrFmIjY3VOSgiosY4nJCJ/0T9BQD45On+8HZvI25ABICz2kQkLYo7t8tWb5i6eBybtfWl0Rvk3U0ulzf4nJeXV5ODISJqrKSsIsy/8+3Tq8O64DlffvskFdWz2tVfQFXPaq9duxZTp07F888/L3KERNRaaDQC5u2IR8qtEnRysMRaNmvrVaP/ZseMGYPTp08/8LyioiJ89tlnWLt2rU6BERE1pKC0otZSgf8a11vskOgunNUmIqlYFfUXoq7k3GnW9kM724a/HCfdNXrGIiQkBM8++ywcHBzwxBNPwM/PD506dYKlpSXy8/Nx+fJlnDhxAocOHcL48eOxfPlyfcZNRK2UWiPgre+qlgp0a8ulAqWIs9pEJAVHErNqbpcNe6Y/+ruxWVvfGl1YvPbaa5g4cSJ2796NnTt3YtOmTSgsLAQAyGQy9OnTB0FBQTh37hx69+a3h0SkH58fvoLjf92CpbkJNr3ix6UCJWLMmDH48MMP8dBDD933vKKiIqxbtw62traYNWtWC0VHRK1Nck5xze2yU4Z2wTM+vF22JWjVYyGXyzFx4kRMnDgRAFBYWIiysjK0a9cO5ubmWr/5sWPHsHz5csTGxiIzMxP79u1DcHBwg+dHR0djxIgRdY5nZmbCxcVF6/cnIsNyIP4mNh67BgBY/pw3+nSyFzkiqsZZbSKSiqpm7RgUKyvh7+mIf43nF94tpUnN29UcHBx0WpO8pKQE3t7emDp1Kp555plGX5eUlAR7+79/oXBycmpyDERkGC5nKLBw70UAwBuB3fCEdyeRI6K7cVabiKRAoxEwf+cFXMstQUcHS6x72QfmvF22xWhVWPznP/+p97iDgwN69uyJgIAArd587NixGDt2rFbXAFWFRJs2bbS+jogMU2GpCjO/jUW5SoNHe3bAP0fzPn0pau5ZbSIibX31a3LN3kYbJvqiPZu1W5RWhcXKlSvrPV5QUIDCwkIMHToUP/zwAxwdHZsluIYMHDgQSqUS/fr1w4cffohhw4Y1eK5SqYRSqax5rFAoAAAqlQoqlUqr960+X9vrpMYY8mAO0qHvPDQaAXN3xiEtrxRubSzxxbP9oFFXQqNuvvfgZ6Gf3HWd1SYi0sYvl7Ox8pc/AQAfB/fj3kYi0KqwSElJafC5a9euYeLEiXjvvfewbt06nQOrT8eOHbFhwwb4+flBqVRi8+bNCAwMxJkzZ+Dj41PvNWFhYVi6dGmd40eOHIG1tXWT4oiMjGzSdVJjDHkwB+nQVx5H0mU4esMUZjIBL7oX42S0/v6+WvNnUVpaqvP7NvesNvvwiKixruYWY97OeADApIDOCPFzFzegVkqnHou7de3aFZ9++immTp3aXC9Zh5eXV62lCocOHYqrV69i5cqV2LZtW73XhIaGYv78+TWPFQoF3N3dMXr06Fp9Go2hUqkQGRmJUaNGGfS0vjHkwRykQ595nEi+jUOnq/Y9WPZUX4ToaRM8fhZ/z+bqorlntdmHR0SNUVSuwuvfxKBIWQn/Lo54//E+YofUajVbYQEAHh4eyMrKas6XfCB/f3+cOHGiweflcnm9a6qbm5s3+RcIXa6VEmPIgzlIR3PncbOgDPN3X4QgAC/4ueOlhzyb7bUb0po/i+bIu7lntdmHR0QPotEIeGfXBVzNLYGLvSXWsllbVM36N3/p0iV07ty5OV/ygeLj49GxY8cWfU8i0i9lpRpvfhuL/FIV+rs6YOlTfcUOiXRUPat95MgRvb/XwIED0bFjR4waNQq///673t+PiMSz9mgyjlzOhoWpCdZP9EEHOzZri0mrGYuGpsoLCwsRGxuLd955B5MnT2706xUXFyM5ObnmcUpKCuLj4+Ho6AgPDw+Ehobi5s2b+OabbwAAq1atgqenJ/r27Yvy8nJs3rwZv/76a4sMVETUcpb97zIupBeijbU51r3sA0tzU7FDomag71ntpvThcYGP2piDdBhDHvrO4WhSLr6806z94RO90a+jrV7eq7V/Ftpco1Vh0aZNG8hksnqfk8lkmDZtGhYtWtTo14uJianVaFfdCzF58mSEh4cjMzMTaWlpNc9XVFTgnXfewc2bN2FtbY0BAwbgl19+qbdZj4gM097YdGw/kwaZDFj1wkC4OzZtkQWSHn3PajelD48LfNSPOUiHMeShjxxyyoAvL5lCEGQY5qyBTfYFHDp0odnf526t9bPQZnEPrQqLo0eP1nvc3t4ePXr0gKWlJXJyctCpU+M2rgoMDIQgCA0+Hx4eXuvxu+++i3fffbfR8RKRYfkzuwj/2n8JADDnsR4I9GLTrSFp7lnt5vCgPjwu8FEbc5AOY8hDXzkUKysRsvEMytQl8PFog02v+sHCTH99Fa39s9BmcQ+tCotHH330vs9fuHABPj4+UKubcYF5ImoVSisq8eb28yhXaTC8Zwe8/Y8eYodEWmruWe3m8KA+PC7wUT/mIB3GkEdz5iAIAkJ3XERybgmc7eXYMNEXNlYt01fRWj8Lbc5v1lWhiIiaasmBRCTnFMPJTo4vn/eGiUn9v6CSdDX3rDb78IjoXuuir+JwYhbMTWVYP9EXTvaWYodEd2FhQUSi+/58OnbHpsNEBvxnwiC0t+WqHoaouWe12YdHRHc7mpSDL44kAQCWPdUPPh5tRY6I7sXCgohElZxTjPf2JwAA5o7siYe6thM5IpIK9uERUbXUWyWY810cBAGY4O+BCf4eYodE9dCqsLh48eJ9n09KStIpGCJqXcpVasyOOI/SCjWGdmuHWSO6ix0SERFJTImyEjO2xUJRXgkfjzb48EnurC1VWhUWAwcOhEwmq/cbpOrjDTXuERHda+n/LuNKVhHa21pg1YsDYcq+CiIiuosgCFiw5wKSsovQwU6O9RN9ITfj3kZSpVVhkZKSoq84iKiV+eFCBr47W71fxSA42bEBz9BxVpuImtuG367h0KWqZu0NE33gzGZtSdOqsNDnxkZE1Hpcv12Cxd9X7Vcxe0R3PNyjvcgRUXPgrDYRNaff/szF5z9fAQB8+GRf+HZ2FDkiehCtCovPP/8cb731FqysrAAAv//+O/z8/GrWAC8qKsLChQuxbt265o+UiIxCpVqDeTvjUayshH8XR8x5jPtVGAvOahNRc0m7XYq37zRrvzjYHS+xWdsgaFVYhIaGYsqUKTWFxdixYxEfH4+uXbsCqNrye+PGjSwsiKhB66Ov4nxaAezkZvjyBW+Ymepvt1RqWZzVJqLmUFpRide3xaCwTIWB7m2w9Km+nO00EFqN6PdOb99vGUAiontdTC/A6qi/AADLgvvCra21yBGRvhw/fhwTJ05EQEAAbt68CQDYtm0bTpw4IXJkRCRlgiDg3T0X7yzsUbWzNpu1DQe/KiSiFlFWocbcnfGo1AgYP6Ajgge6ih0S6cnevXsRFBQEKysrxMXFQalUAgAKCwvxySefiBwdEUnZf49fw8GLmTAzkWH9RB+4OLBZ25CwsCCiFvHJoT9wLbcELvaW+Di4H6e1jdi///1vbNiwAf/9739hbm5ec3zYsGE4f/68iJERkZQd/ysXn/5U1ay95Ik+GNyFzdqGRuudtzdv3gxbW1sAQGVlJcLDw9G+fdWKLkVFRc0bHREZhaNJOdh2+joA4IsQb7SxthA5ItKnpKQkDB8+vM5xBwcHFBQUtHxARCR5N/JK8dZ3cdAIQIivGyY+xJ4tQ6RVYeHh4YH//ve/NY9dXFywbdu2OucQEVXLK6nAu3uq9jd4dVgXLi3bCri4uCA5ORldunSpdfzEiRM1i30QEVUrq1Dj9W2xKChVwdvNAR9xVttgaVVYpKam6ikMIjJGgiAg9PuLyC1SooeTLRaO6SV2SNQCpk+fjjlz5mDLli2QyWTIyMjAqVOn8M477+CDDz4QOzwikhBBELBw70X8kalAe1sLrJ/oC0tzNmsbKq0Ki/Lycvzyyy94/PHHAVQtP1vdlAcAZmZmWLZsGSwt2WhDRMDu2HT8nJgNc1MZVr04kINFK7Fo0SJoNBo89thjKC0txfDhwyGXy7FgwQJMmzZN7PCISEK+PpGCHy5kwMxEhrUv+aBTGyuxQyIdaNW8HR4ejo0bN9Y8XrNmDU6ePIm4uDjExcVh27Zt3MOCiABUbW609IdEAMD8UV7o28lB5IiopchkMvzrX/9CXl4eEhIScPr0aeTm5sLBwQGenp5ih0dEEnEy+RY+OfQHAOD9x/tgSNd2IkdEutKqsNi+fTtef/31WsciIiJw9OhRHD16FMuXL8fu3bsb/XrHjh3DE088gU6dOkEmk2H//v0PvCY6Oho+Pj6Qy+Xo3r07wsPDtUmBiFqAWiNg/q54lFSo4d/FEa8P5331rYFSqURoaCj8/PwwbNgwHDp0CH369EFiYiK8vLywevVqzJs3T+wwiUgC0vNLMSviPDQC8KyPGyYFsFnbGGhVWCQnJ6N///41jy0tLWFi8vdL+Pv74/Lly41+vZKSEnh7e2Pt2rWNOj8lJQXjx4/HiBEjEB8fj7lz52LatGn4+eefG58EEendht+uIuZ6PmzlZljxvDdMTdiE1xp88MEHWL9+Pbp06YKUlBSEhITg9ddfx8qVK7FixQqkpKRg4cKFYodJRCIrq1BjxrZY5Jeq0N/VAR8/zWZtY6FVj0VBQUGtnorc3Nxaz2s0mlrPP8jYsWMxduzYRp+/YcMGeHp6YsWKFQCA3r1748SJE1i5ciWCgoIa/TpEpD+X0guxMvJPAMDSJ/vC3ZG7a7cWu3fvxjfffIMnn3wSCQkJGDBgACorK3HhwgX+0kBEAP5e1CMxQ4F2NhbY+AqbtY2JVjMWbm5uSEhIaPD5ixcvws3NTeegGnLq1CmMHDmy1rGgoCCcOnVKb+9JRI1XVqHGnJ1xqNQIGNffBc/4cHft1iQ9PR2+vr4AgH79+kEul2PevHksKoioxtbfU7E/PgOmJjKsYbO20dFqxmLcuHH44IMPMH78+DorP5WVlWHp0qUYP358swZ4t6ysLDg7O9c65uzsDIVCgbKyMlhZ1f3HqVQqa82iKBQKAIBKpYJKpdLq/avP1/Y6qTGGPJiDdNydxyc/J+Nabgmc7OT48PFeqKysFDm6xjHGz6Kp1+pCrVbDwuLvzQ/NzMxqNlQlIjp59RY+vtOs/a9xvRHQjc3axkarwmLx4sXYtWsXvLy8MHv2bPTs2RNA1S6ra9asQWVlJRYvXqyXQJsqLCwMS5curXP8yJEjsLZu2i0akZGRuoYlCcaQB3OQjv/s+gXfXqmazn7WrRSnon8ROSLtGctn0ZQ8SktLdX5fQRAwZcoUyOVyAFVLlM+cORM2Nja1zvv+++91fi8iMiw3C8owOyIOao2Apwe54tVhXcQOifRAq8LC2dkZJ0+exBtvvIFFixZBEAQAVUsLjho1CuvWraszo9CcXFxckJ2dXetYdnY27O3t652tAKr22pg/f37NY4VCAXd3d4wePRr29vZavb9KpUJkZCRGjRoFc3Nz7ROQCGPIgzlIh0qlwr5DkdiTbgWgAq885IH54w1rIzxj+iyamkf1bK4uJk+eXOvxxIkTdXq9Y8eOYfny5YiNjUVmZib27duH4ODg+14THR2N+fPnIzExEe7u7njvvfcwZcoUneIgIt2Uq9SYuS0WeSUV6NvJHmHP9OctkkZKq8ICADw9PXH48GHk5eUhOTkZANC9e3c4Ojo2e3D3CggIwKFDh2odi4yMREBAQIPXyOXymm/P7mZubt7kXyB0uVZKjCEP5iA+QRCw85oJbhVXoLuTLf41vg/MDbQRz9A/i2pNyaM58t66davOr3G36pUDp06dimeeeeaB51evHDhz5kxs374dUVFRmDZtGjp27MgFPohEIgjABz9cxqWbhWhrbc5mbSOndWFRzdHREf7+/jq9eXFxcU1xAlQNCvHx8XB0dISHhwdCQ0Nx8+ZNfPPNNwCAmTNnYs2aNXj33XcxdepU/Prrr9i1axd+/PFHneIgoqb7Pi4DF/NMYGYiw6oXuLs2NR+uHEhk+I5nybAvNROmd3bWdmvLlQKNWZMLi+YQExODESNG1DyuvmVp8uTJCA8PR2ZmJtLS0mqe9/T0xI8//oh58+Zh9erVcHNzw+bNmzlgEInkRl4pPjp0BQAw5x/d0M+Vu2uTeBpaOXDu3LkNXsMFPmpjDtJhDHmc/CsH+1KrFiBdGNQTgzs7GGQ+xvBZtNTiHqIWFoGBgTV9GvWpb1ftwMBAxMXF6TEqImoMtUbAvJ3xKFGq0dVOwPRHPMUOiVq5pqwcyAU+6sccpMNQ88hXAl9cNIUGMvi218ApPxGHDiWKHZZODPWzuJu+F/cQtbAgIsNVvbu2jdwUE7srubs2GSQu8FEbc5AOQ85DqVLjpa/PobhSAVdrAZumB8Le2vLBF0qUIX8W1VpqcQ8WFkSktYSbf++u/f64XrDKuiByRERNWzmQC3zUjzlIh6HlIQgCQvdfxsWbCrSxMsdrXmWwt7Y0qBwaYmifRX30vbiHVjtvExGVq9SYuzMelRoBY/q64JlBncQOiQhA1cqBUVFRtY49aOVAImpe356+jj2x6TCRAateGIB2hjtRQU3AwoKItPLpT1eQnFOMDnZyfMK1yEmPiouLER8fj/j4eAB/rxxYvahHaGgoJk2aVHP+zJkzce3aNbz77ru4cuUK1q1bh127dmHevHlihE/U6pxNycPS/10GACwa2wvDuLN2q8PCgoga7difuQg/mQoAWP7cADjaWIgbEBm1mJgYDBo0CIMGDQJQtXLgoEGD8MEHHwBAgysHRkZGwtvbGytWrODKgUQtJLOwDG9uj0WlRsAT3p0w/ZGuYodEImCPBRE1Sl5JBd7ZXdVLMSmgMwK9nESOiIwdVw4kMgzKSjVmfnset4or0MvFDp89y9ns1oozFkT0QIIgYNHei8gtUqK7ky0Wj+stdkhERCQBgiDgg/2JuHCjAA5W5tj0ih+sLfi9dWvFwoKIHmjnuRs4cjkb5qYyrH6Ru2sTEVGV7WfSsDPmBkxkwFcTBsGjHXfWbs1YWBDRfaXcKqlpxvvnaC/07cTdtYmICIhJzcPS/1VtevfumF4Y3rODyBGR2FhYEFGDVGoN5u6IQ5lKjYCu7diMR0REAIBsRTne2H4eKrWA8f07YsZwjg/EwoKI7uM/UX/hQnoh7C3NsOJ5b5hwd20iolavqlk7FrlFSvRyscPnzw1gszYBYGFBRA04l5qHtUeTAQCfPNMfndrUv3MxERG1Lh/+cBlxaQWwtzTDxld8YSNnszZVYWFBRHUoylWYtzMeGgF4xscVjw/g7tpERAREnEnDd2fTIJMB/5kwCJ3b2YgdEkkICwsiqkUQBIR+fwnp+WVwd7TC0if7ih0SERFJQOz1fCz5IQFA1WIe3M+I7sXCgohq+e7sDfx4MRNmJjKsfnEQ7CzNxQ6JiIhElqMoxxvfxkKlFjC2nwveDOwmdkgkQSwsiKjGH5mKu5YO9IKPR1uRIyIiIrFVVGrwxvbzyClSoqezLb4I8WazNtWLhQURAQBKlJWYHXEeykoNRnh1wLSHuXQgEREBS/+XiNjr+bCzNMPGV/zYrE0NYmFBRACADw4k4mpuCZzt5Vjx/EAuLUtERNhxNg3bz9xp1n5xEDzbs1mbGsbCgoiwJzYde8+nw+TOwOFoYyF2SEREJLK4tHx8cKDq9th3RvXEiF5s1qb7k0RhsXbtWnTp0gWWlpYYMmQIzp492+C54eHhkMlktf5YWlq2YLRExiUpqwjv769a5WPeyJ4Y0rWdyBEREZHYcorK8ca351Gh1iCorzPeDOwudkhkAEQvLHbu3In58+djyZIlOH/+PLy9vREUFIScnJwGr7G3t0dmZmbNn+vXr7dgxETGo7BMhRnbYlCmUuPh7u3x5ggOHERErV1FpQaztp9HlqIc3Z1seXssNZrohcWXX36J6dOn49VXX0WfPn2wYcMGWFtbY8uWLQ1eI5PJ4OLiUvPH2dm5BSMmMg4ajYB3dsUj9XYpXNtY4T8TBsGUAwcRUav37x8v41xqPuzkZtj0ii9s2axNjSTqv5SKigrExsYiNDS05piJiQlGjhyJU6dONXhdcXExOnfuDI1GAx8fH3zyySfo27f+TbyUSiWUSmXNY4VCAQBQqVRQqVRaxVt9vrbXSY0x5MEcdLfm6FX88kcOLMxMsOZFb9hZyJoUi9h5NAdjyAHQLQ9Dz52ImseumBv45lTVnSCrXhyIrh1sRY6IDImohcWtW7egVqvrzDg4OzvjypUr9V7j5eWFLVu2YMCAASgsLMQXX3yBoUOHIjExEW5ubnXODwsLw9KlS+scP3LkCKytrZsUd2RkZJOukxpjyIM5NM3lfBk2XTEBIMOznVVIu3ACaRd0e01+FtLRlDxKS0v1EAkRGZILNwrw3l09d4/15h0hpB2Dm9sKCAhAQEBAzeOhQ4eid+/e2LhxIz766KM654eGhmL+/Pk1jxUKBdzd3TF69GjY29tr9d4qlQqRkZEYNWoUzM0NdzdiY8iDOTRd6u0SfLDxDARU4sXBblj2ZB+dXo+fhXTokkf1bC4RtU65RUrM2BaLikoNRvVxxlv/YM8daU/UwqJ9+/YwNTVFdnZ2rePZ2dlwcXFp1GuYm5tj0KBBSE5Orvd5uVwOuVxe73VN/QVCl2ulxBjyYA7aKSxVYca38Sgsq8RA9zZY+lQ/mJuZNstr87OQjqbkYQx5E1HTqNQazIqoatbu2sEGXz7vzWZtahJRm7ctLCzg6+uLqKiommMajQZRUVG1ZiXuR61W49KlS+jYsaO+wiQyCiq1Bm9GxOLarRJ0crDEpkm+kDdTUUGkL1yOnEj/Pv7xD5xNyYOt3AybXvGDnSW/aKCmEf1WqPnz52Py5Mnw8/ODv78/Vq1ahZKSErz66qsAgEmTJsHV1RVhYWEAgGXLluGhhx5C9+7dUVBQgOXLl+P69euYNm2amGkQSZogCPjwh0T8nnwb1ham2Dx5MJzs+AsXSVv1cuQbNmzAkCFDsGrVKgQFBSEpKQlOTvVv1GVvb4+kpKSaxzIZv3Ulup89sekIP5kKAFj5wkB0d2KzNjWd6IXFCy+8gNzcXHzwwQfIysrCwIEDcfjw4ZqG7rS0NJiY/D2xkp+fj+nTpyMrKwtt27aFr68vTp48iT59dLtPnMiYhZ9MxfYzaZDJgNUvDkKfTtr1FxGJ4e7lyAFgw4YN+PHHH7FlyxYsWrSo3muqlyMnoge7lF6IxfsuAQDmPNYDo/qwWZt0I3phAQCzZ8/G7Nmz630uOjq61uOVK1di5cqVLRAVkXH4OTELHx28DAAIHduLAwcZhJZYjhzgkuT3Yg7Soe88bpdU4PVtMaio1GCEV3u8ObxLs78XPwvpaKnlyCVRWBCRfpy5dhtvfRcHjQBM8HfH9Ee6ih0SUaO0xHLkAJckbwhzkA595KHWAOv+MEGmwgROlgKC7LNw+PBPzf4+1fhZSIe+lyNnYUFkpK5kKTDtm6pvo0b2dsZHT/Xj/eZk1LRdjhzgkuT3Yg7Soc88Pj50BcmKNNhYmOL/pg/RW18FPwvpaKnlyFlYEBmh9PxSTN5yFkXllRjcpS3WvDQIZqaiLgJHpJWWWI4c4JLkDWEO0tHceeyLS0f4qTQAwIrnB6K3a9tme+2G8LOQDn0vR87fNIiMTE5ROSZtOYtshRI9nW2xedJgWJpzWVkyLFyOnKj5JdwsxKK9Vc3ab/2jO8b040IH1Lw4Y0FkRG4VK/Hyf8/gWm4JXNtY4f+m+sPB2rC/XaHWi8uREzWfvJIKzNgWC2WlBiO8OmDeyJ5ih0RGiIUFkZHIK6nAxM1n8FdOMVzsLRExfQg6OliJHRZRk3E5cqLmUanWYHbEedwsKEOXdtZY9eIg7qxNesHCgsgIFJRWFRVXsorQwU6OiOlD0LmdjdhhEemMy5ET6e7Tn67g5NWqDVI3TfKDgxVnskk/2GNBZOBuFyvx8uYzuJypQHtbC3w3fQi6duDOqUREBByIv4nNJ1IAACtCvNHT2U7kiMiYccaCyIBlFpZh4uYzuJpbgnY2Ftg+7SF0d+KgQUREQGJGIRbuvQgAmDWiG8b250IGpF8sLIgMVMqtEkzcfAY3C8rQycES26YNQTfOVBAREYD8O83a5SoNHu3ZAfNHeYkdErUCLCyIDNDlDAUmbTmLW8VKdG1vg23ThsC1DRu1iYioqln7re/ikJ5fhs7trPGfFwfBlM3a1AJYWBAZmOikHMyOiEOxshK9O9rjm6n+6GBXd4MvIiJqnZb/nIQTybeqmrVf8eOy49RiWFgQGZBtp69jyYEEaAQgoGs7bHjFl6t7EBFRjf9dyMDGY9cAAMuf84aXC/vuqOWwsCAyAGqNgE8O/YGv76zsEeLrho+f7g8LMy7sRkREVS5nKPDunqpm7ZmPdsP4AWzWppbFwoJI4vJLKjBnZzyO/ZkLAFgQ5IU3A7tBJuP9skREVKWgtAIzvo1BmUqNR3q0x4IgNmtTy2NhQSRhF9ML8Ma3VbulWpqbYPlz3njCu5PYYRERkYSoNQLe+i4ON/LK4O5oha8msFmbxMHCgkiCBEHAjnM3sORAIirUGnRpZ431E33Ru6O92KEREZHELP85Ccf/ugUr86pm7TbWFmKHRK0UCwsiiSksVeFf+y/h4MVMAMCoPs74IsSbTdpERFTHwYsZ2PDbVQDAZ88N4BdQJCpJdH6uXbsWXbp0gaWlJYYMGYKzZ8/e9/zdu3ejV69esLS0RP/+/XHo0KEWipRIv35PvoWgVcdw8GImTE1keHeMFzZO5MpPRERU15UsBRbsrmrWnjG8K57krbIkMtELi507d2L+/PlYsmQJzp8/D29vbwQFBSEnJ6fe80+ePIkJEybgtddeQ1xcHIKDgxEcHIyEhIQWjpyo+ZRWVGLZ/y7j5c1nkKUoh2d7G+x9YyjeDOwOE94nS0RE9ygsVWHGtliUqdR4uDubtUkaRC8svvzyS0yfPh2vvvoq+vTpgw0bNsDa2hpbtmyp9/zVq1djzJgxWLBgAXr37o2PPvoIPj4+WLNmTQtHTtQ8fvszF6O+PIYtv1ctJfvSEA/8+PbDGOjeRtzAiIhIktQaAW/viMP126Vwa1vVrG1mKvqvdETi9lhUVFQgNjYWoaGhNcdMTEwwcuRInDp1qt5rTp06hfnz59c6FhQUhP379+szVADA/vgMxGbLUBKbDjPTO391slr/U2sJ0L+P3fO/d56pb7XQ6uvrXFvPNfeeg3vOufvl737dSnUlEvJlsEzKhbmZaa3XvzcnE5kMFmYmkJuZQG5m+vd/m1c9lt95zKVPtZdTpMT//WmC86fiAACubazw7+B+GNHLSeTIiIhIyr6MTMJvf+bC0twEG1/xRVsbNmuTNIhaWNy6dQtqtRrOzs61jjs7O+PKlSv1XpOVlVXv+VlZWfWer1QqoVQqax4rFAoAgEqlgkql0ireZQevoEhpih3XLmt1nTSZ4r9X4prllcxNZbC3NIeDlRnsrczhYGkOeyszONnJ4WxvCRd7OVzsLeHiYIkOthbN8q1K9Wen7WcoBeUqNb7+/To2HktBmcoEJjJgckBnzPlHN9jIzQwuJ0P+LKoZQw6AbnkYeu5ErcVPlzKx9uidZu1nB6BvJweRIyL6m9GvChUWFoalS5fWOX7kyBFYW1tr9Vo9bE1QYQ0Idx4LQu3n73l43+cbf66sGV+r9vP3Hq/vmEYAKjVA5Z3/Vd3138Kd2FRqAbdLKnC7pKKeV6zNVCagvSXgZCnAyQpwthLQyVpAR2ugKZtIR0ZGan+RSDQCEHtLhoNpJiioqPq762wr4DlPNTyEq/gt6qrIEerGkD6LhhhDDkDT8igtLdVDJETUnP7MLsI7uy8AAKY97ImnBrqKHBFRbaIWFu3bt4epqSmys7NrHc/OzoaLi0u917i4uGh1fmhoaK1bpxQKBdzd3TF69GjY22u3JNuoUSpERkZi1KhRMDc33FV6VCrd8xAEASq1AGWlGsVKNQrLVCgsU0FRVonC8qr/zlEoka1QIktRjixFObIVSlRqgOwyILtMBuT//XrmpjJ4Oduhbyd79He1x0A3B/Rwsm2wcbk5cmgplWoNfryUhXW/XcO1W1W/vHV0sMS8f3SFeeZFBI2Wfg73Y0ifRUOMIQdAtzyqZ3OJSJoKy1R4/ZsYlFaoMbRbOywa20vskIjqELWwsLCwgK+vL6KiohAcHAwA0Gg0iIqKwuzZs+u9JiAgAFFRUZg7d27NscjISAQEBNR7vlwuh1wur3Pc3Ny8yb9A6HKtlOiahwUAGwCOdo07X6MRkFFYhqu5JbiWW4xruSVIzilGYkYhFOWVSMhQICFDgZ0xVec7WJljcJe2GNzFEf6ejujn6gDze26jkvJnUVpRif1xGdh8/Bqu3SoBUJXT68O74rWHPWEKDQ4duijpHLRhDHkYQw5A0/IwhryJjJVGI2Dujjik3i6FaxsrrHnJh83aJEmi3wo1f/58TJ48GX5+fvD398eqVatQUlKCV199FQAwadIkuLq6IiwsDAAwZ84cPProo1ixYgXGjx+PHTt2ICYmBps2bRIzDWoEExMZ3Npaw62tNR7t2aHmuCAIuJFXhks3C3HpZiEuphcg/kYBCstU+OWPHPzyR9XSw1bmpvDp3AZDPNvB18MelRqxMrm/tNul2HY6FTvP3YCivBIA0MbaHNMf6YpJAZ1hZ1n1C5xKJdEEiIhIUlb+8ieOJuVCblbVrO3IZm2SKNELixdeeAG5ubn44IMPkJWVhYEDB+Lw4cM1DdppaWkwMfm7Kh86dCgiIiLw3nvvYfHixejRowf279+Pfv36iZUC6Ugmk8GjnTU82llj/ICOAACVWoPEDAXOpeThTEoeYq7noaBUhd+Tb+P35NsAADOZKXZmn0NAt/YY0tURPh5tYWluKkoO+SUV+PFSJg7E38S51L/v8fJwtMakgM540d8DtnLR/+9GZHDWrl2L5cuXIysrC97e3vjqq6/g7+/f4Pm7d+/G+++/j9TUVPTo0QOfffYZxo0b14IREzWvI5ez8dWvyQCAT5/tj36ubNYm6ZLEbzqzZ89u8Nan6OjoOsdCQkIQEhKi56hITOamJhjo3gYD3dtg+vCu0GgE/JlThLMpeThzLQ+nr93G7ZIKnE3Nx9nUfCAKsDA1gbe7A4Z4tqspNGz09Mu8IAj4M7sYR5NyEJ2Ug5jUfFRqqlrfZTLgkR4dMGVoZwT2dOIGd0RNVL2B6oYNGzBkyBCsWrUKQUFBSEpKgpNT3WWZqzdQDQsLw+OPP46IiAgEBwfj/Pnz/PKJDFJWKfCfvVUbAE8d5omnB7mJHBHR/UmisCB6EBMTGXq52KOXiz0mBXRBRUUFwr//CZYe/RFzvRBnUm4jW6HEudR8nEvNx5qjgIkM8Gxvg94d7e/8sYOHow3c2lppNbNRUanBjfxSpN4qQWKGAnFp+Yi/UYD80trLc/btZI/gga54wrsTXBwsm/uvgKjVuXsDVQDYsGEDfvzxR2zZsgWLFi2qc/7dG6gCwEcffYTIyEisWbMGGzZsaNHYiXRVVK7C10mmKKlQ46Gujggdx2Ztkj4WFmSQZDIZnK2AcYPdMWloVwiCgOu3S3Em5TbOXKu6fepmQVWj+NXcEhy8mFnr+va2cjjZyWFvZQZ7S3NYW1QVGgKqdjQtLFMhv7QC+SUqZCnKodbUXZxXbmaCgG7tMMLLCYFeHdC5nU1LpE7UKrTUBqrNtdfRieTbOHgxAzdvmuDY95dq3cJrSDQaDXOQiAs3CpBTLoOLvRyrQvoDGjVUGrXYYWmFewRJR0vtc8TCgoyCTCZDl/Y26NLeBi8M9gAA5CjKcTlTgT8yi3A5U4G/sotwI68UJRVq3CpW4lax8gGv+jcrc1N4trdBD2dbDHRvg0EebdG7ox3kZuL0dBAZu5bYQBVovr2OojNl2JdqCsAEyMl84PnSxhykwlwmYGLnEpw5FiV2KDppzXsESY2+9zliYUFGy8neEk72lgj0+vtebEGomo24kVeG2yVKKMoroShTobSiEiayql4IE5kMDlbmaGtjDgcrC7i1tYKTnRwyGXsliIxNc+115JZeiM5/5SI5+S90794Dpgb6Tblao2EOEiEIGpjl/okpwYa7vw73CJKOltrniIUFtSoymQxtrC3QxppL9RFJWUtsoAo0315Hvp7tMcDNAYfK/sS4Ed0N+pcP5iANKpUKhw79aRT76xhDDoBx5KHvfY4Mt5QnIiKjdfcGqtWqN1BtaEPU6g1U73a/DVSJiKh5ccaCiIgkiRuoEhEZFhYWREQkSdxAlYjIsLCwICIiyeIGqkREhoM9FkREREREpDMWFkREREREpLNWdyuUIFTtoKzNmrzVVCoVSktLoVAoDHq5MWPIgzlIhzHkYQw5ALrlUf0zsfpnZGvV2scI5iAdxpCHMeQAGEceLTU+tLrCoqioCADg7u4uciRERNJTVFQEBwcHscMQDccIIqL6NWZ8kAmt7OspjUaDjIwM2NnZab2TcvWOrDdu3NBqR1apMYY8mIN0GEMexpADoFsegiCgqKgInTp1qrXSUmvT2scI5iAdxpCHMeQAGEceLTU+tLoZCxMTE7i5uen0Gvb29gb7D+tuxpAHc5AOY8jDGHIAmp5Ha56pqMYxogpzkA5jyMMYcgCMIw99jw+t92spIiIiIiJqNiwsiIiIiIhIZywstCCXy7FkyRLI5XKxQ9GJMeTBHKTDGPIwhhwA48nDUBnD3z9zkA5jyMMYcgCMI4+WyqHVNW8TEREREVHz44wFERERERHpjIUFERERERHpjIUFERERERHpjIVFEz355JPw8PCApaUlOnbsiFdeeQUZGRlih6WV1NRUvPbaa/D09ISVlRW6deuGJUuWoKKiQuzQtPLxxx9j6NChsLa2Rps2bcQOp9HWrl2LLl26wNLSEkOGDMHZs2fFDkkrx44dwxNPPIFOnTpBJpNh//79YoektbCwMAwePBh2dnZwcnJCcHAwkpKSxA5LK+vXr8eAAQNq1iYPCAjATz/9JHZYrZ6hjxHGMj4AhjlGcHwQnzGMD0DLjxEsLJpoxIgR2LVrF5KSkrB3715cvXoVzz33nNhhaeXKlSvQaDTYuHEjEhMTsXLlSmzYsAGLFy8WOzStVFRUICQkBG+88YbYoTTazp07MX/+fCxZsgTnz5+Ht7c3goKCkJOTI3ZojVZSUgJvb2+sXbtW7FCa7LfffsOsWbNw+vRpREZGQqVSYfTo0SgpKRE7tEZzc3PDp59+itjYWMTExOAf//gHnnrqKSQmJoodWqtm6GOEsYwPgOGNERwfpMEYxgdAhDFCoGZx4MABQSaTCRUVFWKHopPPP/9c8PT0FDuMJtm6davg4OAgdhiN4u/vL8yaNavmsVqtFjp16iSEhYWJGFXTARD27dsndhg6y8nJEQAIv/32m9ih6KRt27bC5s2bxQ6D7mIMY4Qhjw+CYDhjBMcHaTKW8UEQ9DtGcMaiGeTl5WH79u0YOnQozM3NxQ5HJ4WFhXB0dBQ7DKNWUVGB2NhYjBw5suaYiYkJRo4ciVOnTokYGRUWFgKAwf5/QK1WY8eOHSgpKUFAQIDY4dAdxjJGcHzQP44P0mXo4wPQMmMECwsdLFy4EDY2NmjXrh3S0tJw4MABsUPSSXJyMr766ivMmDFD7FCM2q1bt6BWq+Hs7FzruLOzM7KyskSKijQaDebOnYthw4ahX79+YoejlUuXLsHW1hZyuRwzZ87Evn370KdPH7HDavWMaYzg+NAyOD5IkyGPD0DLjhEsLO6yaNEiyGSy+/65cuVKzfkLFixAXFwcjhw5AlNTU0yaNAmCBPYb1DYPALh58ybGjBmDkJAQTJ8+XaTI/9aUHIh0MWvWLCQkJGDHjh1ih6I1Ly8vxMfH48yZM3jjjTcwefJkXL58WeywjI4xjBHGMD4AHCOoZRny+AC07BjBnbfvkpubi9u3b9/3nK5du8LCwqLO8fT0dLi7u+PkyZOi34KgbR4ZGRkIDAzEQw89hPDwcJiYiF9vNuWzCA8Px9y5c1FQUKDn6HRTUVEBa2tr7NmzB8HBwTXHJ0+ejIKCAoP8VlMmk2Hfvn218jEks2fPxoEDB3Ds2DF4enqKHY7ORo4ciW7dumHjxo1ih2JUjGGMMIbxATDeMYLjg/QY2/gA6HeMMGv2VzRgHTp0QIcOHZp0rUajAQAolcrmDKlJtMnj5s2bGDFiBHx9fbF161bJDBq6fBZSZ2FhAV9fX0RFRdX8oNVoNIiKisLs2bPFDa6VEQQBb731Fvbt24fo6GijGTQ0Go0kfhYZG2MYI4xhfACMd4zg+CAdxjo+APodI1hYNMGZM2dw7tw5PPzww2jbti2uXr2K999/H926dRN9tkIbN2/eRGBgIDp37owvvvgCubm5Nc+5uLiIGJl20tLSkJeXh7S0NKjVasTHxwMAunfvDltbW3GDa8D8+fMxefJk+Pn5wd/fH6tWrUJJSQleffVVsUNrtOLiYiQnJ9c8TklJQXx8PBwdHeHh4SFiZI03a9YsRERE4MCBA7Czs6u5h9nBwQFWVlYiR9c4oaGhGDt2LDw8PFBUVISIiAhER0fj559/Fju0VssYxghjGR8AwxsjOD5IgzGMD4AIY4Re1poychcvXhRGjBghODo6CnK5XOjSpYswc+ZMIT09XezQtLJ161YBQL1/DMnkyZPrzeHo0aNih3ZfX331leDh4SFYWFgI/v7+wunTp8UOSStHjx6t9+998uTJYofWaA39+9+6davYoTXa1KlThc6dOwsWFhZChw4dhMcee0w4cuSI2GG1asYwRhjL+CAIhjlGcHwQnzGMD4LQ8mMEeyyIiIiIiEhn0rlhkoiIiIiIDBYLCyIiIiIi0hkLCyIiIiIi0hkLCyIiIiIi0hkLCyIiIiIi0hkLCyIiIiIi0hkLCyIiIiIi0hkLCyIiIiIi0hkLCyIiIiIi0hkLCyIiIiIi0hkLCyIiIiIi0hkLC6IWlpubCxcXF3zyySc1x06ePAkLCwtERUWJGBkREYmJ4wMZOpkgCILYQRC1NocOHUJwcDBOnjwJLy8vDBw4EE899RS+/PJLsUMjIiIRcXwgQ8bCgkgks2bNwi+//AI/Pz9cunQJ586dg1wuFzssIiISGccHMlQsLIhEUlZWhn79+uHGjRuIjY1F//79xQ6JiIgkgOMDGSr2WBCJ5OrVq8jIyIBGo0FqaqrY4RARkURwfCBDxRkLIhFUVFTA398fAwcOhJeXF1atWoVLly7ByclJ7NCIiEhEHB/IkLGwIBLBggULsGfPHly4cAG2trZ49NFH4eDggIMHD4odGhERiYjjAxky3gpF1MKio6OxatUqbNu2Dfb29jAxMcG2bdtw/PhxrF+/XuzwiIhIJBwfyNBxxoKIiIiIiHTGGQsiIiIiItIZCwsiIiIiItIZCwsiIiIiItIZCwsiIiIiItIZCwsiIiIiItIZCwsiIiIiItIZCwsiIiIiItIZCwsiIiIiItIZCwsiIiIiItIZCwsiIiIiItIZCwsiIiIiItIZCwsiIiIiItLZ/wPT7uWa1cKgZAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''对比ReLU和GELU函数'''\n",
    "import torch\n",
    "gelu, relu = GELU(), nn.ReLU()\n",
    "\n",
    "# 测试数据\n",
    "x = torch.linspace(-3, 3, 1000)\n",
    "y_gelu, y_relu = gelu(x), relu(x)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8,3))\n",
    "\n",
    "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"]), 1):\n",
    "    plt.subplot(1, 2, i)\n",
    "    plt.plot(x, y)\n",
    "    plt.title(f\"{label}\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(f\"{label}(x)\")\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d151dd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''FFN前向传播网络'''\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"])\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "201d4d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "'''124M GPT-2的参数设置'''\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50527, #vocabulary size\n",
    "    \"context_length\": 1024, #context length\n",
    "    \"emb_dim\": 768, #embedding dimension\n",
    "    \"n_heads\": 12, #number of attention heads\n",
    "    \"n_layers\": 12, #number of layers(transformer blocks)\n",
    "    \"drop_rate\": 0.1, #dropout rate\n",
    "    \"qkv_bias\": False #query-key-value bias\n",
    "}\n",
    "\n",
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "\n",
    "# Dummy input:[batch_size, num_token, emb_size]\n",
    "x = torch.randn(2, 3, 768)\n",
    "\n",
    "out = ffn(x)\n",
    "\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4f8ea9",
   "metadata": {},
   "source": [
    "# 4.shortcut connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c115b165",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''带/不带 跳跃连接深度神经网络'''\n",
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer_sizes, use_shortcut):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU())\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            # 1.计算当前layer的输出\n",
    "            layer_output = layer(x)\n",
    "            # 2.检查是否启用跳跃连接\n",
    "            if self.use_shortcut and x.shape == layer_output.shape:\n",
    "                x = x + layer_output  # <—— 将输入与当前层的输出相加，作为下一层的输入\n",
    "            else:\n",
    "                x = layer_output\n",
    "        \n",
    "        return x\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebed94bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义打印梯度的函数\n",
    "def print_gradients(model, x):\n",
    "    # Forward pass\n",
    "    output = model(x)\n",
    "    target = torch.tensor([[0.]])\n",
    "\n",
    "    # Calculate loss based on how close the target\n",
    "    # and output are\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(output, target)\n",
    "    \n",
    "    # Backward pass to calculate the gradients\n",
    "    loss.backward()\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            # Print the mean absolute gradient of the weights\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a84f74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.00020471324387472123\n",
      "layers.1.0.weight has gradient mean of 0.0001231795467901975\n",
      "layers.2.0.weight has gradient mean of 0.0007344747427850962\n",
      "layers.3.0.weight has gradient mean of 0.0013871216215193272\n",
      "layers.4.0.weight has gradient mean of 0.005026496481150389\n",
      "==================================================\n",
      "layers.0.0.weight has gradient mean of 0.29920274019241333\n",
      "layers.1.0.weight has gradient mean of 0.2749510407447815\n",
      "layers.2.0.weight has gradient mean of 0.454661101102829\n",
      "layers.3.0.weight has gradient mean of 0.3629586696624756\n",
      "layers.4.0.weight has gradient mean of 1.763088583946228\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "layer_sizes = [3, 3, 3, 3, 3, 1]  \n",
    "\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "\n",
    "torch.manual_seed(123)\n",
    "# 1. 不带跳跃连接的 DNN\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(\n",
    "    layer_sizes=layer_sizes,\n",
    "    use_shortcut=False\n",
    ")\n",
    "\n",
    "print_gradients(model_without_shortcut, sample_input)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 2. 带跳跃连接的DNN\n",
    "torch.manual_seed(123)\n",
    "model_with_shortcut = ExampleDeepNeuralNetwork(\n",
    "    layer_sizes=layer_sizes,\n",
    "    use_shortcut=True\n",
    ")\n",
    "print_gradients(model_with_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70f3daa",
   "metadata": {},
   "source": [
    "# 5. transformer block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db845003",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MulitHeadAttention import MultiHeadAttention\n",
    "import torch.nn as nn\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        # 1.多头注意力模块\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out = cfg[\"emb_dim\"],\n",
    "            context_length = cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"]\n",
    "        )\n",
    "\n",
    "        # 2.FFN模块\n",
    "        self.ff = FeedForward(cfg)\n",
    "\n",
    "        # 3.Layer Normalization模块，分别设置的原因是其中有可学习的参数\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "\n",
    "        # 4.dropout\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Step 1:多头注意力机制, 启用跳跃连接\n",
    "        shortcut = x\n",
    "\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "\n",
    "        x = x + shortcut #将输入加在输出上，作为下一个模块的输入\n",
    "\n",
    "        # Step 2:前向传播网络，启用跳跃连接\n",
    "        shortcut = x\n",
    "\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "\n",
    "        x = x + shortcut \n",
    "\n",
    "\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e61cc7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "'''测试Transformer block的输出'''\n",
    "\n",
    "# 124M GPT-2的参数设置\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50527, #vocabulary size\n",
    "    \"context_length\": 1024, #context length\n",
    "    \"emb_dim\": 768, #embedding dimension\n",
    "    \"n_heads\": 12, #number of attention heads\n",
    "    \"n_layers\": 12, #number of layers(transformer blocks)\n",
    "    \"drop_rate\": 0.1, #dropout rate\n",
    "    \"qkv_bias\": False #query-key-value bias\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "x = torch.rand(2, 4, 768)\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "\n",
    "output = block(x)\n",
    "\n",
    "print(x.shape)\n",
    "print(output.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e65606",
   "metadata": {},
   "source": [
    "# 6.GPT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f902b1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''GPT模型类的实现'''\n",
    "import torch.nn as nn\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "\n",
    "        # 1.token and position embedding\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "\n",
    "        # 2. dropout layer\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        # 3. transformer blocks\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "\n",
    "        # 4. layer normalization\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "\n",
    "        # 5. output linear layer\n",
    "\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias = False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        # 这里之所以用torch.arange()，是为了处理输入的seq_len < context_length的情况\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        \n",
    "        x = self.drop_emb(x)\n",
    "        \n",
    "        x = self.trf_blocks(x)\n",
    "        \n",
    "        x = self.final_norm(x)\n",
    "        \n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f14d87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "torch.Size([2, 4, 50527])\n",
      "tensor([[[-0.5877,  0.8573, -0.2601,  ...,  0.3107,  0.4342,  0.8528],\n",
      "         [ 0.0712, -0.1176,  0.2643,  ...,  0.1433, -0.3264, -0.1630],\n",
      "         [-0.6378,  0.0947, -0.2607,  ..., -0.2314, -0.9811,  0.3972],\n",
      "         [-0.2141,  0.2604, -0.2470,  ...,  0.2904, -0.5390,  0.2703]],\n",
      "\n",
      "        [[-0.7258,  0.6511,  0.3790,  ..., -0.1726,  0.0351,  1.0781],\n",
      "         [ 0.5047,  0.4110, -0.2189,  ..., -0.4933, -0.4000,  0.5538],\n",
      "         [ 0.2778,  0.2747,  0.0131,  ...,  0.5906,  0.2540,  0.9131],\n",
      "         [ 0.4185,  0.6752, -0.4666,  ...,  0.6094, -0.1796,  0.8730]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "'''测试GPT模型'''\n",
    "import tiktoken\n",
    "\n",
    "# 1.构造数据\n",
    "tokenizer  = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "batch = []\n",
    "\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "\n",
    "batch = torch.stack(batch, dim = 0)\n",
    "\n",
    "print(batch)\n",
    "\n",
    "# 2.得到模型输出\n",
    "torch.manual_seed(123)\n",
    "# 124M GPT-2的参数设置\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50527, #vocabulary size\n",
    "    \"context_length\": 1024, #context length\n",
    "    \"emb_dim\": 768, #embedding dimension\n",
    "    \"n_heads\": 12, #number of attention heads\n",
    "    \"n_layers\": 12, #number of layers(transformer blocks)\n",
    "    \"drop_rate\": 0.1, #dropout rate\n",
    "    \"qkv_bias\": False #query-key-value bias\n",
    "}\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "output = model(batch)\n",
    "print(output.shape)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d9c883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163424256\n",
      "torch.Size([50527, 768])\n",
      "torch.Size([50527, 768])\n",
      "124619520\n"
     ]
    }
   ],
   "source": [
    "'''计算模型的参数量'''\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(total_params)\n",
    "\n",
    "# Note:\n",
    "# 可以发现，计算出来的参数量是163M，这和官方给的124M不一样，原因是GPT-2模型使用了\n",
    "# 权重绑定技术,将token embedding layer和output layer的参数权重共享了，因为它们的shape\n",
    "# 是一样的。\n",
    "print(model.tok_emb.weight.shape)\n",
    "print(model.out_head.weight.shape)\n",
    "\n",
    "# 那么，如果将token embedding layer或者output layer的参数，减掉其中一个，就可以了\n",
    "total_params_gpt2 = total_params - sum(p.numel() for p in model.out_head.parameters())\n",
    "print(total_params_gpt2) #这才是实际的模型参数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cadbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "623.4140625\n"
     ]
    }
   ],
   "source": [
    "'''计算模型的内存占用量'''\n",
    "# 假设使用float32精度，每个参数占4个字节（byte）。\n",
    "total_size_bytes = total_params * 4\n",
    "\n",
    "# 转换为M\n",
    "total_size_M = total_size_bytes / (1024 * 1024)\n",
    "print(total_size_M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c20d8d2",
   "metadata": {},
   "source": [
    "## 练习"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479b440e",
   "metadata": {},
   "source": [
    "### 练习4.1 计算多头注意力模块和输出头模块的参数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12b2a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85026816\n",
      "38804736\n",
      "123831552\n"
     ]
    }
   ],
   "source": [
    "attn_params = sum(p.numel() for p in model.trf_blocks.parameters())\n",
    "print(attn_params)\n",
    "\n",
    "ffn_params = sum(p.numel() for p in model.out_head.parameters())\n",
    "print(ffn_params)\n",
    "\n",
    "print(attn_params + ffn_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdd9953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerBlock(\n",
      "  (att): MultiHeadAttention(\n",
      "    (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ff): FeedForward(\n",
      "    (layers): Sequential(\n",
      "      (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (1): GELU()\n",
      "      (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (norm1): LayerNorm()\n",
      "  (norm2): LayerNorm()\n",
      "  (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "2360064\n",
      "4722432\n"
     ]
    }
   ],
   "source": [
    "# 计算 一个 transformer block中多头注意力模块和FFN模块的参数量\n",
    "transformer_block = TransformerBlock(GPT_CONFIG_124M)\n",
    "print(transformer_block)#输出transformer block的结构\n",
    "\n",
    "# 计算多头注意力模块的参数量\n",
    "mha_params = sum(p.numel() for p in transformer_block.att.parameters())\n",
    "print(mha_params)\n",
    "\n",
    "# 计算前向传播网络模块的参数量\n",
    "ffn_params = sum(p.numel() for p in transformer_block.ff.parameters())\n",
    "print(ffn_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e7a845",
   "metadata": {},
   "source": [
    "1.上述一个transformer block参数量计算的过程：\n",
    "<div align=\"center\" >\n",
    "    <img src=\"./images/transformer_block参数量计算过程.jpg\">\n",
    "</div>\n",
    "\n",
    "2.Linear层参数量计算方式\n",
    "<div align=\"center\">\n",
    "    <img src=\"./images/Linear层参数量计算方式.jpg\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e0e871",
   "metadata": {},
   "source": [
    "\n",
    "### 练习4.2 不同size的GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dca8d97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''不同大小模型的参数设置'''\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}\n",
    "\n",
    "\n",
    "def get_config(base_config, model_name=\"gpt2-small\"):\n",
    "    GPT_CONFIG = base_config.copy()\n",
    "\n",
    "    if model_name == \"gpt2-small\":\n",
    "        GPT_CONFIG[\"emb_dim\"] = 768\n",
    "        GPT_CONFIG[\"n_layers\"] = 12\n",
    "        GPT_CONFIG[\"n_heads\"] = 12\n",
    "\n",
    "    elif model_name == \"gpt2-medium\":\n",
    "        GPT_CONFIG[\"emb_dim\"] = 1024\n",
    "        GPT_CONFIG[\"n_layers\"] = 24\n",
    "        GPT_CONFIG[\"n_heads\"] = 16\n",
    "\n",
    "    elif model_name == \"gpt2-large\":\n",
    "        GPT_CONFIG[\"emb_dim\"] = 1280\n",
    "        GPT_CONFIG[\"n_layers\"] = 36\n",
    "        GPT_CONFIG[\"n_heads\"] = 20\n",
    "\n",
    "    elif model_name == \"gpt2-xl\":\n",
    "        GPT_CONFIG[\"emb_dim\"] = 1600\n",
    "        GPT_CONFIG[\"n_layers\"] = 48\n",
    "        GPT_CONFIG[\"n_heads\"] = 25\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Incorrect model name {model_name}\")\n",
    "\n",
    "    return GPT_CONFIG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4e94b105",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''计算模型的 size'''\n",
    "def calculate_size(model): # based on chapter code\n",
    "    \n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Total number of parameters: {total_params:,}\")\n",
    "\n",
    "    total_params_gpt2 =  total_params - sum(p.numel() for p in model.out_head.parameters())\n",
    "    print(f\"Number of trainable parameters considering weight tying: {total_params_gpt2:,}\")\n",
    "    \n",
    "    # Calculate the total size in bytes (assuming float32, 4 bytes per parameter)\n",
    "    total_size_bytes = total_params * 4\n",
    "    \n",
    "    # Convert to megabytes\n",
    "    total_size_mb = total_size_bytes / (1024 * 1024)\n",
    "    \n",
    "    print(f\"Total size of the model: {total_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "06e5a6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "gpt2-small:\n",
      "Total number of parameters: 163,009,536\n",
      "Number of trainable parameters considering weight tying: 124,412,160\n",
      "Total size of the model: 621.83 MB\n",
      "\n",
      "\n",
      "gpt2-medium:\n",
      "Total number of parameters: 406,212,608\n",
      "Number of trainable parameters considering weight tying: 354,749,440\n",
      "Total size of the model: 1549.58 MB\n",
      "\n",
      "\n",
      "gpt2-large:\n",
      "Total number of parameters: 838,220,800\n",
      "Number of trainable parameters considering weight tying: 773,891,840\n",
      "Total size of the model: 3197.56 MB\n",
      "\n",
      "\n",
      "gpt2-xl:\n",
      "Total number of parameters: 1,637,792,000\n",
      "Number of trainable parameters considering weight tying: 1,557,380,800\n",
      "Total size of the model: 6247.68 MB\n"
     ]
    }
   ],
   "source": [
    "for model_abbrev in (\"small\", \"medium\", \"large\", \"xl\"):\n",
    "    model_name = f\"gpt2-{model_abbrev}\"\n",
    "    CONFIG = get_config(GPT_CONFIG_124M, model_name=model_name)\n",
    "    model = GPTModel(CONFIG)\n",
    "    print(f\"\\n\\n{model_name}:\")\n",
    "    calculate_size(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
