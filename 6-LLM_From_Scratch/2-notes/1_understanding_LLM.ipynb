{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.引言\n",
    "1.LLM的成功主要源自于Transformer架构，以及大量的数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 什么是LLM?\n",
    "1.LLM就是用来理解，生成和回复人类文本的神经网络。<br>\n",
    "2.大模型的“大”，有两层含义：model size和dataset size。<br>\n",
    "3.大模型又被叫做generative artificial intelligence(AI), 缩写为generative AI或者GenAI.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 LLM的应用有哪些？\n",
    "LLM可以应用于任何切分和生成文本的任务中，并且应用范围还在不断地被扩大。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 构建LLM的阶段"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 预训练（Pretraining）：\n",
    "1.指的是在一个large, diverse的数据集上进行训练。<br>\n",
    "2.这个数据集是原始的无标签的文本数据集。<br>\n",
    "3.预训练结束之后，模型会具备基础的两个能力：文本补全（text completion）和few-shot能力。\n",
    "（1）后者的意思是模型可以在仅有少量训练样本的情况下，在新的任务上表现良好，而无需这些新任务对应的大量训练数据。<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 微调（Finetuning）：\n",
    "1.微调指的是在某个具体任务的，很小的有标签数据集上进行训练。<br>\n",
    "2.两个最常用的微调方式：指令微调（instruction-finetuning）和对分类任务的微调（finetuning for classification tasks）。<br>\n",
    "(1)指令微调就是有标签的数据包含了多个成对的指令和答案。<br>\n",
    "(2)分类微调指的是有标签数据集中包含了文本以及对应的分类标签。<br>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
