{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.建模长序列的问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.RNN模型的介绍：<br>\n",
    "（1）RNN模型是一种将前序步骤的输出作为当前步骤的输入的神经网络，这种特性使得RNN适用于序列数据（比如文本）；<br>\n",
    "\n",
    "（2）RNN是一种encoder-decoder模型，当输入的文本被送进encoder之后，会进行如下的处理过程：<br>\n",
    "encoder会在每一个step都更新自己的隐藏状态（hidden state），这个隐藏状态实际上那个就是hidden layers里的值，将整个输入序列的信息都传入最终的一个隐藏状态。这个部分的作用就是将输入的整个文本处理进一个hidden state，也叫做记忆单元（memory cell）。<br>\n",
    "\n",
    "decoder就是将这一个最终的hidden state作为输入，将其用于生成输出的序列，生成的过程是一次只输出一个token的，也就是token by token的。这部分的作用就是利用encoder阶段得到的hidden state生成输出。<br>\n",
    "\n",
    "（3）RNN的缺陷：<br>\n",
    "RNN在decoder处理的阶段，无法直接访问encoder中的前序隐藏状态，而是只能依赖于encoder中得到的最终那一个hidden state（其中封装了输入序列中的所有相关信息）。这就会导致丢失上下文的信息，特别是在复杂的句子中，词与词之间的依赖关系跨越的距离非常大的情况下。<br>\n",
    "\n",
    "2.在LLM出来之前，没有注意力机制的模型有哪些问题？<br>\n",
    "正如上面介绍的RNN模型的缺陷：丢失上下文信息和无法建立长程依赖。以文本翻译为例，RNN这种逐词翻译的模型的效果就会很差，因为它在decoder阶段无法保留上下文信息和语言的语法结构。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.通过注意力机制捕捉数据依赖"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Bahdanau attention mechanism：<br>\n",
    "这是在2014年提出的RNN的改进方法，主要的改进之处在于：<br>\n",
    "decoder可以在每一个decoding step，有选择性地去access输入序列中的任意部分token，并且在access的时候，可以通过注意力权重/分数（attention weights/scores），对输入序列中的不同token进行重要性衡量，进而对生成输出的token产生不同的重要性影响。<br>\n",
    "\n",
    "2.2017年提出的transformer就是在bahdanau注意力机制的基础上改进的，使用了self-attention机制。<br>\n",
    "\n",
    "3.Self-attention mechanism：就是在计算输入序列的表示（representation）的时候，允许输入序列中的每个位置都能够关注当前相同序列中的其他任意位置。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.使用自注意力关注输入中的不同部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.self-attention中的self指的是在一个输入序列中，通过将不同的位置关联起来，进而计算得到注意力权重。它可以评估和学习输入中各个部分之间的关系和依赖性。<br>\n",
    "自注意力与传统的注意力机制不一样，传统的注意力机制是关注两个不同序列中的元素之间的关系，就比如上面提到的bahdanau注意力机制就是关注的输出序列中的某个元素和输入序列中所有元素之间的关系。<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
